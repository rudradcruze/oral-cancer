{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T09:45:40.490044Z",
     "start_time": "2025-06-12T08:21:46.514096Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage import exposure, filters, morphology, segmentation, color\n",
    "from skimage.restoration import denoise_bilateral, denoise_nl_means\n",
    "from skimage.transform import rotate\n",
    "from scipy import ndimage\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib parameters for Times New Roman font\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 24\n",
    "plt.rcParams['figure.dpi'] = 1000\n",
    "\n",
    "class HistopathologyPreprocessor:\n",
    "    def __init__(self, input_dir, output_dir):\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.classes = ['normal', 'oscc']\n",
    "        \n",
    "        # Create output directories for each preprocessing technique\n",
    "        self.techniques = [\n",
    "            'original',\n",
    "            'gaussian_blur',\n",
    "            'bilateral_filter',\n",
    "            'nlm_denoising',\n",
    "            'histogram_equalization',\n",
    "            'clahe',\n",
    "            'gamma_correction',\n",
    "            'contrast_enhancement',\n",
    "            'brightness_adjustment',\n",
    "            'color_normalization',\n",
    "            'edge_enhancement',\n",
    "            'morphological_opening',\n",
    "            'morphological_closing',\n",
    "            'gaussian_noise',\n",
    "            'salt_pepper_noise',\n",
    "            'rotation_augmentation',\n",
    "            'stain_normalization',\n",
    "            'median_filter',\n",
    "            'unsharp_masking',\n",
    "            'adaptive_threshold'\n",
    "        ]\n",
    "        \n",
    "        self.create_output_directories()\n",
    "    \n",
    "    def create_output_directories(self):\n",
    "        \"\"\"Create output directories for each technique and class\"\"\"\n",
    "        for technique in self.techniques:\n",
    "            for class_name in self.classes:\n",
    "                dir_path = os.path.join(self.output_dir, technique, class_name)\n",
    "                os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Load image as RGB\"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "    \n",
    "    def save_image(self, image, technique, class_name, filename):\n",
    "        \"\"\"Save processed image\"\"\"\n",
    "        output_path = os.path.join(self.output_dir, technique, class_name, filename)\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "        return output_path\n",
    "    \n",
    "    def gaussian_blur(self, image, kernel_size=5):\n",
    "        \"\"\"Apply Gaussian blur\"\"\"\n",
    "        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "    def bilateral_filter(self, image, d=9, sigma_color=75, sigma_space=75):\n",
    "        \"\"\"Apply bilateral filter for noise reduction while preserving edges\"\"\"\n",
    "        return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n",
    "    \n",
    "    def nlm_denoising(self, image):\n",
    "        \"\"\"Apply Non-Local Means denoising\"\"\"\n",
    "        # Convert to float for skimage processing\n",
    "        image_float = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Check scikit-image version and use appropriate parameter\n",
    "        try:\n",
    "            # For newer versions of scikit-image (>= 0.19)\n",
    "            denoised = denoise_nl_means(image_float, h=0.1, fast_mode=True, channel_axis=-1)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                # For older versions that still support multichannel\n",
    "                denoised = denoise_nl_means(image_float, h=0.1, fast_mode=True, multichannel=True)\n",
    "            except TypeError:\n",
    "                # Fallback: process each channel separately\n",
    "                result = np.zeros_like(image_float)\n",
    "                for i in range(3):\n",
    "                    result[:, :, i] = denoise_nl_means(image_float[:, :, i], h=0.1, fast_mode=True)\n",
    "                denoised = result\n",
    "        \n",
    "        return (denoised * 255).astype(np.uint8)\n",
    "    \n",
    "    def histogram_equalization(self, image):\n",
    "        \"\"\"Apply histogram equalization to each channel\"\"\"\n",
    "        result = np.zeros_like(image)\n",
    "        for i in range(3):\n",
    "            result[:, :, i] = cv2.equalizeHist(image[:, :, i])\n",
    "        return result\n",
    "    \n",
    "    def clahe(self, image, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        \"\"\"Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\"\"\"\n",
    "        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "        result = np.zeros_like(image)\n",
    "        for i in range(3):\n",
    "            result[:, :, i] = clahe.apply(image[:, :, i])\n",
    "        return result\n",
    "    \n",
    "    def gamma_correction(self, image, gamma=1.2):\n",
    "        \"\"\"Apply gamma correction\"\"\"\n",
    "        gamma_corrected = np.power(image / 255.0, gamma)\n",
    "        return (gamma_corrected * 255).astype(np.uint8)\n",
    "    \n",
    "    def contrast_enhancement(self, image, alpha=1.3):\n",
    "        \"\"\"Enhance contrast\"\"\"\n",
    "        enhanced = cv2.convertScaleAbs(image, alpha=alpha, beta=0)\n",
    "        return enhanced\n",
    "    \n",
    "    def brightness_adjustment(self, image, beta=20):\n",
    "        \"\"\"Adjust brightness\"\"\"\n",
    "        adjusted = cv2.convertScaleAbs(image, alpha=1.0, beta=beta)\n",
    "        return adjusted\n",
    "    \n",
    "    def color_normalization(self, image):\n",
    "        \"\"\"Normalize color channels\"\"\"\n",
    "        result = np.zeros_like(image, dtype=np.float32)\n",
    "        for i in range(3):\n",
    "            channel = image[:, :, i].astype(np.float32)\n",
    "            mean = np.mean(channel)\n",
    "            std = np.std(channel)\n",
    "            result[:, :, i] = (channel - mean) / (std + 1e-8)\n",
    "        \n",
    "        # Rescale to 0-255\n",
    "        result = ((result - result.min()) / (result.max() - result.min()) * 255).astype(np.uint8)\n",
    "        return result\n",
    "    \n",
    "    def edge_enhancement(self, image):\n",
    "        \"\"\"Enhance edges using unsharp masking\"\"\"\n",
    "        # Convert to grayscale for edge detection, then apply to all channels\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        edges = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        edges = np.uint8(np.absolute(edges))\n",
    "        \n",
    "        # Apply edge enhancement to each channel\n",
    "        result = np.zeros_like(image)\n",
    "        for i in range(3):\n",
    "            result[:, :, i] = cv2.addWeighted(image[:, :, i], 1.0, edges, 0.3, 0)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def morphological_opening(self, image, kernel_size=5):\n",
    "        \"\"\"Apply morphological opening\"\"\"\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "        result = np.zeros_like(image)\n",
    "        for i in range(3):\n",
    "            result[:, :, i] = cv2.morphologyEx(image[:, :, i], cv2.MORPH_OPEN, kernel)\n",
    "        return result\n",
    "    \n",
    "    def morphological_closing(self, image, kernel_size=5):\n",
    "        \"\"\"Apply morphological closing\"\"\"\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "        result = np.zeros_like(image)\n",
    "        for i in range(3):\n",
    "            result[:, :, i] = cv2.morphologyEx(image[:, :, i], cv2.MORPH_CLOSE, kernel)\n",
    "        return result\n",
    "    \n",
    "    def add_gaussian_noise(self, image, std=25):\n",
    "        \"\"\"Add Gaussian noise\"\"\"\n",
    "        noise = np.random.normal(0, std, image.shape).astype(np.int16)\n",
    "        noisy_image = image.astype(np.int16) + noise\n",
    "        noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "        return noisy_image\n",
    "    \n",
    "    def add_salt_pepper_noise(self, image, noise_ratio=0.05):\n",
    "        \"\"\"Add salt and pepper noise\"\"\"\n",
    "        result = image.copy()\n",
    "        h, w, c = image.shape\n",
    "        \n",
    "        # Salt noise\n",
    "        num_salt = np.ceil(noise_ratio * image.size * 0.5)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape[:2]]\n",
    "        result[coords[0], coords[1], :] = 255\n",
    "        \n",
    "        # Pepper noise\n",
    "        num_pepper = np.ceil(noise_ratio * image.size * 0.5)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape[:2]]\n",
    "        result[coords[0], coords[1], :] = 0\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def rotation_augmentation(self, image, angle=15):\n",
    "        \"\"\"Apply rotation augmentation\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, rotation_matrix, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "        return rotated\n",
    "    \n",
    "    def stain_normalization(self, image):\n",
    "        \"\"\"Simple stain normalization using histogram matching\"\"\"\n",
    "        # Convert to LAB color space\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        \n",
    "        # Normalize each channel\n",
    "        result = np.zeros_like(lab, dtype=np.float32)\n",
    "        for i in range(3):\n",
    "            channel = lab[:, :, i].astype(np.float32)\n",
    "            # Normalize to mean=128, std=30 for L channel, mean=128, std=20 for a,b channels\n",
    "            target_mean = 128\n",
    "            target_std = 30 if i == 0 else 20\n",
    "            \n",
    "            current_mean = np.mean(channel)\n",
    "            current_std = np.std(channel)\n",
    "            \n",
    "            if current_std > 0:\n",
    "                normalized = (channel - current_mean) / current_std * target_std + target_mean\n",
    "                result[:, :, i] = np.clip(normalized, 0, 255)\n",
    "            else:\n",
    "                result[:, :, i] = channel\n",
    "        \n",
    "        # Convert back to RGB\n",
    "        result = result.astype(np.uint8)\n",
    "        rgb_result = cv2.cvtColor(result, cv2.COLOR_LAB2RGB)\n",
    "        return rgb_result\n",
    "    \n",
    "    def median_filter(self, image, kernel_size=5):\n",
    "        \"\"\"Apply median filter\"\"\"\n",
    "        result = np.zeros_like(image)\n",
    "        for i in range(3):\n",
    "            result[:, :, i] = cv2.medianBlur(image[:, :, i], kernel_size)\n",
    "        return result\n",
    "    \n",
    "    def unsharp_masking(self, image, strength=1.5, radius=1, threshold=0):\n",
    "        \"\"\"Apply unsharp masking\"\"\"\n",
    "        # Create Gaussian blur\n",
    "        blurred = cv2.GaussianBlur(image, (0, 0), radius)\n",
    "        \n",
    "        # Create unsharp mask\n",
    "        unsharp_mask = cv2.addWeighted(image, 1 + strength, blurred, -strength, 0)\n",
    "        \n",
    "        return unsharp_mask\n",
    "    \n",
    "    def adaptive_threshold(self, image):\n",
    "        \"\"\"Apply adaptive thresholding (convert to grayscale first, then back to RGB)\"\"\"\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Apply adaptive threshold\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Convert back to RGB\n",
    "        result = cv2.cvtColor(thresh, cv2.COLOR_GRAY2RGB)\n",
    "        return result\n",
    "    \n",
    "    def process_image(self, image_path, filename):\n",
    "        \"\"\"Process a single image with all techniques\"\"\"\n",
    "        image = self.load_image(image_path)\n",
    "        class_name = os.path.basename(os.path.dirname(image_path))\n",
    "        \n",
    "        # Dictionary to store processed images for visualization\n",
    "        processed_images = {}\n",
    "        \n",
    "        # Original image\n",
    "        self.save_image(image, 'original', class_name, filename)\n",
    "        processed_images['original'] = image.copy()\n",
    "        \n",
    "        # Apply all preprocessing techniques\n",
    "        techniques_functions = {\n",
    "            'gaussian_blur': lambda img: self.gaussian_blur(img),\n",
    "            'bilateral_filter': lambda img: self.bilateral_filter(img),\n",
    "            'nlm_denoising': lambda img: self.nlm_denoising(img),\n",
    "            'histogram_equalization': lambda img: self.histogram_equalization(img),\n",
    "            'clahe': lambda img: self.clahe(img),\n",
    "            'gamma_correction': lambda img: self.gamma_correction(img),\n",
    "            'contrast_enhancement': lambda img: self.contrast_enhancement(img),\n",
    "            'brightness_adjustment': lambda img: self.brightness_adjustment(img),\n",
    "            'color_normalization': lambda img: self.color_normalization(img),\n",
    "            'edge_enhancement': lambda img: self.edge_enhancement(img),\n",
    "            'morphological_opening': lambda img: self.morphological_opening(img),\n",
    "            'morphological_closing': lambda img: self.morphological_closing(img),\n",
    "            'gaussian_noise': lambda img: self.add_gaussian_noise(img),\n",
    "            'salt_pepper_noise': lambda img: self.add_salt_pepper_noise(img),\n",
    "            'rotation_augmentation': lambda img: self.rotation_augmentation(img),\n",
    "            'stain_normalization': lambda img: self.stain_normalization(img),\n",
    "            'median_filter': lambda img: self.median_filter(img),\n",
    "            'unsharp_masking': lambda img: self.unsharp_masking(img),\n",
    "            'adaptive_threshold': lambda img: self.adaptive_threshold(img)\n",
    "        }\n",
    "        \n",
    "        for technique_name, technique_func in techniques_functions.items():\n",
    "            try:\n",
    "                processed_img = technique_func(image)\n",
    "                self.save_image(processed_img, technique_name, class_name, filename)\n",
    "                processed_images[technique_name] = processed_img.copy()\n",
    "            except Exception as e:\n",
    "                print(f\"Error applying {technique_name} to {filename}: {str(e)}\")\n",
    "        \n",
    "        return processed_images\n",
    "    \n",
    "    def process_dataset(self):\n",
    "        \"\"\"Process the entire dataset\"\"\"\n",
    "        sample_images = {}  # Store sample images for visualization\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.input_dir, class_name)\n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"Warning: Directory {class_dir} does not exist!\")\n",
    "                continue\n",
    "            \n",
    "            image_files = [f for f in os.listdir(class_dir) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp'))]\n",
    "            \n",
    "            print(f\"Processing {len(image_files)} images in {class_name} class...\")\n",
    "            \n",
    "            # Process each image\n",
    "            for filename in tqdm(image_files, desc=f\"Processing {class_name}\"):\n",
    "                image_path = os.path.join(class_dir, filename)\n",
    "                processed_images = self.process_image(image_path, filename)\n",
    "                \n",
    "                # Store the first image as sample for visualization\n",
    "                if class_name not in sample_images:\n",
    "                    sample_images[class_name] = {\n",
    "                        'filename': filename,\n",
    "                        'images': processed_images\n",
    "                    }\n",
    "        \n",
    "        return sample_images\n",
    "    \n",
    "    def create_visualization_figure(self, sample_images, output_path):\n",
    "        \"\"\"Create a figure showing different preprocessing techniques\"\"\"\n",
    "        # Select a subset of techniques for visualization (to fit in the figure)\n",
    "        selected_techniques = [\n",
    "            'original', 'gaussian_blur', 'bilateral_filter', 'histogram_equalization',\n",
    "            'clahe', 'gamma_correction', 'contrast_enhancement', 'edge_enhancement',\n",
    "            'stain_normalization', 'unsharp_masking'\n",
    "        ]\n",
    "        \n",
    "        n_techniques = len(selected_techniques)\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(n_classes, n_techniques, figsize=(n_techniques * 4, n_classes * 4))\n",
    "        fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "        \n",
    "        # Remove any grid settings globally for this figure\n",
    "        plt.rcParams['axes.grid'] = False\n",
    "        \n",
    "        if n_classes == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for class_idx, class_name in enumerate(self.classes):\n",
    "            if class_name in sample_images:\n",
    "                for tech_idx, technique in enumerate(selected_techniques):\n",
    "                    if technique in sample_images[class_name]['images']:\n",
    "                        img = sample_images[class_name]['images'][technique]\n",
    "                        axes[class_idx, tech_idx].imshow(img)\n",
    "                        axes[class_idx, tech_idx].set_title(\n",
    "                            f\"{technique.replace('_', ' ').title()}\", \n",
    "                            fontsize=20, fontname='Times New Roman'\n",
    "                        )\n",
    "                        axes[class_idx, tech_idx].axis('off')\n",
    "                        axes[class_idx, tech_idx].grid(False)\n",
    "                \n",
    "                # Add class label on the left\n",
    "                axes[class_idx, 0].text(-0.1, 0.5, f\"{class_name.upper()}\", \n",
    "                                       rotation=90, fontsize=24, fontname='Times New Roman',\n",
    "                                       ha='center', va='center', transform=axes[class_idx, 0].transAxes)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save as PNG and PDF with high DPI and transparency\n",
    "        plt.savefig(f\"{output_path}.png\", dpi=1000, bbox_inches='tight', \n",
    "                   transparent=True, facecolor='white')\n",
    "        plt.savefig(f\"{output_path}.pdf\", dpi=1000, bbox_inches='tight', \n",
    "                   transparent=True, facecolor='white')\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Visualization figure saved as {output_path}.png and {output_path}.pdf\")\n",
    "\n",
    "# Define paths\n",
    "input_dir = \"dataset/original\"\n",
    "output_dir = \"dataset\"\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = HistopathologyPreprocessor(input_dir, output_dir)\n",
    "\n",
    "# Process the dataset\n",
    "print(\"Starting preprocessing of oral cancer histopathology dataset...\")\n",
    "sample_images = preprocessor.process_dataset()\n",
    "\n",
    "# Create visualization figure\n",
    "print(\"Creating visualization figure...\")\n",
    "preprocessor.create_visualization_figure(\n",
    "    sample_images, \n",
    "    os.path.join(output_dir, \"preprocessing_techniques_comparison\")\n",
    ")\n",
    "\n",
    "print(\"\\nPreprocessing completed successfully!\")\n",
    "print(f\"Processed images saved in: {output_dir}\")\n",
    "print(f\"Applied {len(preprocessor.techniques)} different preprocessing techniques\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing of oral cancer histopathology dataset...\n",
      "Processing 89 images in normal class...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing normal: 100%|██████████| 89/89 [12:48<00:00,  8.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 439 images in oscc class...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing oscc: 100%|██████████| 439/439 [1:09:48<00:00,  9.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating visualization figure...\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
