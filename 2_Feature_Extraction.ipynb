{
 "cells": [
  {
   "cell_type": "code",
   "id": "b3e0a05b816ff8cd",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import platform"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f9b80a82003947c",
   "metadata": {},
   "source": [
    "# Check for MPS availability (Apple Silicon)\n",
    "if hasattr(torch, 'backends') and hasattr(torch.backends, 'mps'):\n",
    "    mps_available = torch.backends.mps.is_available()\n",
    "else:\n",
    "    mps_available = False\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d8f4ef095672f8",
   "metadata": {},
   "source": [
    "# Define paths\n",
    "SEGMENTED_ROOT = \"./dataset/original\"\n",
    "OUTPUT_DIR = \"2_Feature_Extraction/BEiT\"\n",
    "CLASSES = [\"normal\", \"oscc\"]\n",
    "feature_extract_file_name = \"feature_extract_BEiT\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40b7930afa31cfac",
   "metadata": {},
   "source": [
    "# Self-Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "id": "f797a5d7705fd97e",
   "metadata": {},
   "source": [
    "# Define Attention Module\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.key = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W = x.size()\n",
    "\n",
    "        # Reshape and permute query and key for matrix multiplication\n",
    "        proj_query = self.query(x).view(batch_size, -1, H * W).permute(0, 2, 1)\n",
    "        proj_key = self.key(x).view(batch_size, -1, H * W)\n",
    "\n",
    "        # Calculate attention map\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = F.softmax(energy, dim=2)\n",
    "\n",
    "        # Apply attention to value\n",
    "        proj_value = self.value(x).view(batch_size, -1, H * W)\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, H, W)\n",
    "\n",
    "        # Apply gamma parameter and residual connection\n",
    "        out = self.gamma * out + x\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SelfAttentionForSwin(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(SelfAttentionForSwin, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.query = nn.Linear(dim, dim)\n",
    "        self.key = nn.Linear(dim, dim)\n",
    "        self.value = nn.Linear(dim, dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Handle different tensor shapes flexibly\n",
    "        if len(x.shape) == 2:\n",
    "            # If already pooled: [batch_size, channels]\n",
    "            batch_size, c = x.shape\n",
    "            # Add a dummy sequence dimension\n",
    "            x = x.unsqueeze(1)  # [batch_size, 1, channels]\n",
    "            \n",
    "        elif len(x.shape) == 3:\n",
    "            # Expected format: [batch_size, seq_len, channels]\n",
    "            batch_size, seq_len, c = x.shape\n",
    "            \n",
    "        elif len(x.shape) == 4:\n",
    "            # If 4D: [batch_size, height, width, channels] \n",
    "            batch_size, h, w, c = x.shape\n",
    "            x = x.view(batch_size, h * w, c)  # Flatten to sequence\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected tensor shape: {x.shape}\")\n",
    "        \n",
    "        Q = self.query(x)  # [batch_size, seq_len, dim]\n",
    "        K = self.key(x)    # [batch_size, seq_len, dim]\n",
    "        V = self.value(x)  # [batch_size, seq_len, dim]\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.dim ** 0.5)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        \n",
    "        # Apply attention\n",
    "        attended = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        return attended + x"
   ],
   "id": "df9740949f22fa60",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bed43e6e787dac78",
   "metadata": {},
   "source": [
    "# Modified ConvNeXt Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "id": "b38a03a3d1436ae2",
   "metadata": {},
   "source": [
    "# Define Modified ConvNeXt Model with Attention\n",
    "class ModifiedConvNeXt(nn.Module):\n",
    "    def __init__(self, output_dim=2048):\n",
    "        super(ModifiedConvNeXt, self).__init__()\n",
    "        # Load pretrained ConvNeXt Large (instead of tiny)\n",
    "        self.base_model = timm.create_model('convnext_large', pretrained=True)\n",
    "\n",
    "        # Remove the classification head\n",
    "        self.base_model.head = nn.Identity()\n",
    "\n",
    "        # Get the feature dimension\n",
    "        feature_dim = 1536\n",
    "\n",
    "        # Add attention layer at various stages\n",
    "        self.attention1 = SelfAttention(feature_dim)\n",
    "\n",
    "        # New layers for feature extraction\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(feature_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features from ConvNeXt\n",
    "        x = self.base_model.stem(x)\n",
    "        x = self.base_model.stages[0](x)\n",
    "        x = self.base_model.stages[1](x)\n",
    "        x = self.base_model.stages[2](x)\n",
    "        x = self.base_model.stages[3](x)\n",
    "\n",
    "        # Apply attention\n",
    "        x = self.attention1(x)\n",
    "\n",
    "        # Global pooling\n",
    "        x = self.base_model.norm_pre(x)\n",
    "        x = x.mean([-2, -1])  # Global average pooling\n",
    "\n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x)\n",
    "\n",
    "        return features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7c6bc6721778cbf0",
   "metadata": {},
   "source": "# Modified SwinTransformer Model"
  },
  {
   "cell_type": "code",
   "id": "660439db8ab3da01",
   "metadata": {},
   "source": [
    "class ModifiedSwinTransformer(nn.Module):\n",
    "    def __init__(self, output_dim=2048):\n",
    "        super(ModifiedSwinTransformer, self).__init__()\n",
    "        # Load pretrained Swin Transformer Large (224x224 input)\n",
    "        self.base_model = timm.create_model('swin_large_patch4_window7_224', pretrained=True)\n",
    "        \n",
    "        # Remove the classification head\n",
    "        self.base_model.head = nn.Identity()\n",
    "        \n",
    "        # Get the feature dimension (Swin Large has 1536 features)\n",
    "        feature_dim = 1536\n",
    "        \n",
    "        # Add attention layer for the pooled features\n",
    "        self.attention1 = SelfAttentionForSwin(feature_dim)\n",
    "        \n",
    "        # New layers for feature extraction\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(feature_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Use the base model's forward_features method to get features before classification\n",
    "        features = self.base_model.forward_features(x)  # Let's see what shape this returns\n",
    "        \n",
    "        # Apply attention to the features\n",
    "        features = self.attention1(features)\n",
    "        \n",
    "        # Ensure we have the right shape for pooling\n",
    "        if len(features.shape) == 3:\n",
    "            # [B, seq_len, C] -> [B, C]\n",
    "            features = features.mean(dim=1)\n",
    "        elif len(features.shape) == 2:\n",
    "            # Already [B, C]\n",
    "            pass\n",
    "        else:\n",
    "            # Handle other cases by flattening appropriately\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        # Extract final features\n",
    "        final_features = self.feature_extractor(features)\n",
    "        \n",
    "        return final_features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4317f9d56220131f",
   "metadata": {},
   "source": "# Modified BEiT Model"
  },
  {
   "cell_type": "code",
   "id": "2fa777b07816c10d",
   "metadata": {},
   "source": [
    "class CustomBEiT(nn.Module):\n",
    "    def __init__(self, output_dim=1024):\n",
    "        super(CustomBEiT, self).__init__()\n",
    "        # Load pretrained BEiT\n",
    "        self.backbone = timm.create_model('beit_large_patch16_224', pretrained=True)\n",
    "        self.backbone.head = nn.Identity()  # Remove classification head\n",
    "\n",
    "        # Get feature dimension (BEiT Large has 1024 features)\n",
    "        backbone_dim = 1024\n",
    "\n",
    "        # Custom multi-head attention for feature enhancement\n",
    "        self.multihead_attention = nn.MultiheadAttention(backbone_dim, num_heads=8, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(backbone_dim)\n",
    "\n",
    "        # Enhanced feature extraction with residual connections\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(backbone_dim, 1536),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(1536),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(1536, 1280),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(1280),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(1280, output_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features from BEiT\n",
    "        features = self.backbone.forward_features(x)\n",
    "\n",
    "        # BEiT outputs sequence of patches, take CLS token (first token)\n",
    "        if len(features.shape) == 3:  # [B, N, D] where N is number of patches\n",
    "            cls_token = features[:, 0, :]  # Take CLS token\n",
    "        else:\n",
    "            cls_token = features.mean(dim=[2, 3])  # Global average pooling if needed\n",
    "\n",
    "        # Apply multi-head attention for feature enhancement\n",
    "        attended_features, _ = self.multihead_attention(cls_token.unsqueeze(1), cls_token.unsqueeze(1),\n",
    "                                                        cls_token.unsqueeze(1))\n",
    "        attended_features = self.norm1(attended_features.squeeze(1) + cls_token)\n",
    "\n",
    "        # Extract final features\n",
    "        features = self.feature_extractor(attended_features)\n",
    "\n",
    "        return features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2dddee5abf658275",
   "metadata": {},
   "source": [
    "# Define Factorized Convolution for Dimensionality Reduction\n",
    "class FactorizedConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(FactorizedConv, self).__init__()\n",
    "\n",
    "        # Two-step dimensionality reduction\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(in_dim // 2),\n",
    "            nn.Linear(in_dim // 2, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9165e0fe9fa32426",
   "metadata": {},
   "source": [
    "# Define Dataset class\n",
    "class OralCancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, classes, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Collect image paths and labels\n",
    "        for class_idx, class_name in enumerate(classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                        self.labels.append(class_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, img_path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81e9498a91259dd",
   "metadata": {},
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4968dd49a18a4d4e",
   "metadata": {},
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = OralCancerDataset(SEGMENTED_ROOT, CLASSES, transform=transform)\n",
    "# Use fewer workers on macOS to avoid potential issues\n",
    "num_workers = 0 if platform.system() == 'Darwin' else 4\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Print dataset size\n",
    "print(f\"Total number of images: {len(dataset)}\")\n",
    "for class_idx, class_name in enumerate(CLASSES):\n",
    "    count = dataset.labels.count(class_idx)\n",
    "    print(f\"Class {class_name}: {count} images\")\n",
    "\n",
    "# Initialize model\n",
    "if mps_available:\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ade45b0c6c27ecf",
   "metadata": {},
   "source": [
    "model = CustomBEiT(output_dim=1024)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Print model architecture\n",
    "print(\"=\" * 50)\n",
    "print(\"MODIFIED CONVNEXT MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 50)\n",
    "print(model)\n",
    "\n",
    "# Save model architecture to text file\n",
    "model_arch_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_architecture.txt\")\n",
    "with open(model_arch_path, 'w') as f:\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(\"MODIFIED CONVNEXT MODEL ARCHITECTURE\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(str(model) + \"\\n\\n\")\n",
    "\n",
    "    # Print model parameters and save to file\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    f.write(\"MODEL WEIGHTS SUMMARY\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        f.write(f\"Layer: {name}\\n\")\n",
    "        f.write(f\"Shape: {param.shape}\\n\")\n",
    "        f.write(f\"Parameters: {param.numel()}\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        total_params += param.numel()\n",
    "\n",
    "    f.write(f\"Total parameters: {total_params:,}\\n\")\n",
    "    f.write(f\"Total parameters (M): {total_params / 1e6:.2f}M\\n\")\n",
    "\n",
    "print(f\"Model architecture and weights saved to {model_arch_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ff4c98965a2cd8c",
   "metadata": {},
   "source": [
    "# Initialize arrays to store features and labels\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_filenames = []\n",
    "\n",
    "# Extract features\n",
    "with torch.no_grad():\n",
    "    for images, labels, img_paths in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Extract features using the model\n",
    "        features = model(images)\n",
    "\n",
    "        # Store features and labels\n",
    "        all_features.append(features.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "        all_filenames.extend([os.path.basename(path) for path in img_paths])\n",
    "\n",
    "# Concatenate all batches\n",
    "all_features = np.vstack(all_features)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Create DataFrame with features\n",
    "feature_cols = [f'{i + 1}' for i in range(all_features.shape[1])]  # Just use numbers instead of 'feature_X'\n",
    "df = pd.DataFrame(all_features, columns=feature_cols)\n",
    "df['label'] = all_labels\n",
    "df['class'] = [CLASSES[label] for label in all_labels]\n",
    "df['filename'] = all_filenames\n",
    "\n",
    "# Save features to CSV\n",
    "csv_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_features.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Features saved to {csv_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_extractor_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}.pt\")\n",
    "torch.save(model.state_dict(), feature_extractor_path)\n",
    "print(f\"Feature extractor model saved to {feature_extractor_path}\")"
   ],
   "id": "9a0ca10310d994ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "53cc087df1e76528",
   "metadata": {},
   "source": [
    "# Set font to Times New Roman with larger font sizes for all plots\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 18  # Base font size increased\n",
    "plt.rcParams[\"axes.titlesize\"] = 26  # Larger title font\n",
    "plt.rcParams[\"axes.labelsize\"] = 22  # Larger axis labels\n",
    "plt.rcParams[\"xtick.labelsize\"] = 18  # Larger tick labels\n",
    "plt.rcParams[\"ytick.labelsize\"] = 18  # Larger tick labels\n",
    "plt.rcParams[\"legend.fontsize\"] = 20  # Larger legend text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89f50dce045420b1",
   "metadata": {},
   "source": [
    "# Function to save plots in both PDF and PNG formats at 1000 DPI\n",
    "def save_plot(fig, base_path, dpi=1000):\n",
    "    # Save as PNG\n",
    "    png_path = f\"{base_path}.png\"\n",
    "    fig.savefig(png_path, dpi=dpi, bbox_inches='tight')\n",
    "    \n",
    "    # Save as PDF\n",
    "    pdf_path = f\"{base_path}.pdf\"\n",
    "    fig.savefig(pdf_path, dpi=dpi, bbox_inches='tight', format='pdf')\n",
    "    \n",
    "    print(f\"Plot saved to {png_path} and {pdf_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8cf4354e3e3669b5",
   "metadata": {},
   "source": [
    "# Calculate and save statistics\n",
    "stats_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_statistics.txt\")\n",
    "with open(stats_path, 'w') as f:\n",
    "    f.write(\"=== FEATURE EXTRACTION STATISTICS ===\\n\\n\")\n",
    "\n",
    "    # Basic stats\n",
    "    f.write(f\"Total samples: {len(df)}\\n\")\n",
    "    for class_name in CLASSES:\n",
    "        count = len(df[df['class'] == class_name])\n",
    "        f.write(f\"Class {class_name}: {count} samples\\n\")\n",
    "\n",
    "    f.write(\"\\n=== FEATURE STATISTICS ===\\n\\n\")\n",
    "\n",
    "    # Global feature stats\n",
    "    feature_stats = df[feature_cols].describe().T\n",
    "    f.write(\"Global feature statistics:\\n\")\n",
    "    f.write(f\"Mean feature value: {feature_stats['mean'].mean():.4f}\\n\")\n",
    "    f.write(f\"Std of features: {feature_stats['std'].mean():.4f}\\n\")\n",
    "    f.write(f\"Min feature value: {feature_stats['min'].min():.4f}\\n\")\n",
    "    f.write(f\"Max feature value: {feature_stats['max'].max():.4f}\\n\\n\")\n",
    "\n",
    "    # Per-class feature stats\n",
    "    for class_name in CLASSES:\n",
    "        class_features = df[df['class'] == class_name][feature_cols]\n",
    "        f.write(f\"Class {class_name} statistics:\\n\")\n",
    "        f.write(f\"  Mean feature value: {class_features.mean().mean():.4f}\\n\")\n",
    "        f.write(f\"  Std of features: {class_features.std().mean():.4f}\\n\")\n",
    "        f.write(f\"  Min feature value: {class_features.min().min():.4f}\\n\")\n",
    "        f.write(f\"  Max feature value: {class_features.max().max():.4f}\\n\\n\")\n",
    "\n",
    "print(f\"Statistics saved to {stats_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ee96c2d292aef033",
   "metadata": {},
   "source": [
    "# Box Plot of Feature Values"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f3df10677122f20",
   "metadata": {},
   "source": [
    "# Box plots for each class separately with only positive values and distinct colors\n",
    "\n",
    "print(\"Generating separate box plots for each class with only positive values...\")\n",
    "\n",
    "selected_features = feature_cols[:20]  # Select first 25 features\n",
    "scaler = StandardScaler()\n",
    "df_selected = pd.DataFrame(\n",
    "    scaler.fit_transform(df[selected_features]),\n",
    "    columns=selected_features\n",
    ")\n",
    "df_selected['class'] = df['class']\n",
    "\n",
    "# Define distinct colors for each class\n",
    "class_colors = {\n",
    "    \"normal\": \"#1f77b4\",  # Blue\n",
    "    \"oscc\": \"#ff7f0e\",   # Orange\n",
    "}\n",
    "\n",
    "# Create separate box plots for each class\n",
    "for class_name in CLASSES:\n",
    "    class_data = df_selected[df_selected['class'] == class_name]\n",
    "\n",
    "    # Melt the data for visualization\n",
    "    melted_data = class_data.melt(id_vars=['class'], value_vars=selected_features)\n",
    "\n",
    "    # Keep only rows where value is greater than 0\n",
    "    melted_data = melted_data[melted_data['value'] > 0]\n",
    "\n",
    "    # Check if we have any data left after filtering\n",
    "    if len(melted_data) == 0:\n",
    "        print(f\"Warning: No positive values found for {class_name} class. Skipping box plot.\")\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(22, 12))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Use the class-specific color\n",
    "    current_color = class_colors.get(class_name, \"gray\")  # Default to gray if class not found\n",
    "\n",
    "    boxplot = sns.boxplot(\n",
    "        data=melted_data, x='variable', y='value',\n",
    "        showfliers=False, color=current_color\n",
    "    )\n",
    "\n",
    "    plt.title(f'Box Plot of Standardized Features - {class_name} Class (Positive Values Only)',\n",
    "              fontsize=28, pad=25, fontname=\"Times New Roman\")\n",
    "    plt.xlabel('Features', fontsize=24, labelpad=20, fontname=\"Times New Roman\")\n",
    "    plt.ylabel('Standardized Value', fontsize=24, labelpad=20, fontname=\"Times New Roman\")\n",
    "\n",
    "    plt.xticks(fontsize=18, fontname=\"Times New Roman\")\n",
    "    plt.yticks(fontsize=18, fontname=\"Times New Roman\")\n",
    "\n",
    "    # Add a note about removed non-positive values\n",
    "    original_count = len(class_data) * len(selected_features)\n",
    "    remaining_count = len(melted_data)\n",
    "    removed_count = original_count - remaining_count\n",
    "    removed_percentage = (removed_count / original_count) * 100\n",
    "\n",
    "    if removed_count > 0:\n",
    "        plt.figtext(0.5, 0.01,\n",
    "                   f\"Note: {removed_count} non-positive values ({removed_percentage:.1f}%) were removed from the visualization\",\n",
    "                   fontsize=16, fontname=\"Times New Roman\", ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot with higher resolution\n",
    "    boxplot_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_boxplot_{class_name}\")\n",
    "    save_plot(plt.gcf(), boxplot_path)\n",
    "    plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "831e8e03345dc590",
   "metadata": {},
   "source": [
    "# Also create a combined plot with all classes (different colors)\n",
    "print(\"Creating combined box plot with different colors for each class...\")\n",
    "\n",
    "# Combine data for all classes but filter for positive values only\n",
    "all_melted_data = df_selected.melt(id_vars=['class'], value_vars=selected_features)\n",
    "all_melted_data = all_melted_data[all_melted_data['value'] > 0]\n",
    "\n",
    "plt.figure(figsize=(24, 14))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create box plot with hue for class\n",
    "boxplot = sns.boxplot(\n",
    "    data=all_melted_data,\n",
    "    x='variable',\n",
    "    y='value',\n",
    "    hue='class',\n",
    "    palette=class_colors,\n",
    "    showfliers=False\n",
    ")\n",
    "\n",
    "plt.title('Box Plot of Standardized Features by Class (Positive Values Only)',\n",
    "          fontsize=28, pad=25, fontname=\"Times New Roman\")\n",
    "plt.xlabel('Features', fontsize=24, labelpad=20, fontname=\"Times New Roman\")\n",
    "plt.ylabel('Standardized Value', fontsize=24, labelpad=20, fontname=\"Times New Roman\")\n",
    "\n",
    "plt.xticks(fontsize=18, fontname=\"Times New Roman\")\n",
    "plt.yticks(fontsize=18, fontname=\"Times New Roman\")\n",
    "\n",
    "# Move legend to a better position\n",
    "plt.legend(title='Class', title_fontsize=22, fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# Add a note about removed non-positive values\n",
    "original_count = len(df_selected) * len(selected_features)\n",
    "remaining_count = len(all_melted_data)\n",
    "removed_count = original_count - remaining_count\n",
    "removed_percentage = (removed_count / original_count) * 100\n",
    "\n",
    "if removed_count > 0:\n",
    "    plt.figtext(0.5, 0.01,\n",
    "               f\"Note: {removed_count} non-positive values ({removed_percentage:.1f}%) were removed from the visualization\",\n",
    "               fontsize=16, fontname=\"Times New Roman\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save combined plot\n",
    "combined_boxplot_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_boxplot_all_classes_positive_only\")\n",
    "save_plot(plt.gcf(), combined_boxplot_path)\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d1b2efbcc7a7adf",
   "metadata": {},
   "source": [
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "print(\"Computing t-SNE projection...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "features_embedded = tsne.fit_transform(all_features)\n",
    "\n",
    "plt.figure(figsize=(14, 12), dpi=100)\n",
    "for i, class_name in enumerate(CLASSES):\n",
    "    mask = all_labels == i\n",
    "    plt.scatter(features_embedded[mask, 0], features_embedded[mask, 1],\n",
    "                label=class_name, alpha=0.7, s=80)\n",
    "\n",
    "plt.title('t-SNE Visualization of Feature Vectors', fontsize=28, pad=25)\n",
    "plt.xlabel('t-SNE Component 1', fontsize=24, labelpad=20)\n",
    "plt.ylabel('t-SNE Component 2', fontsize=24, labelpad=20)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Border width of the plot and color black\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "    spine.set_color('black')\n",
    "\n",
    "# Move legend outside the frame with increased title font size\n",
    "plt.legend(title='Class', title_fontsize=20, fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot with higher resolution\n",
    "tsne_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_tsne\")\n",
    "save_plot(plt.gcf(), tsne_path)\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c224410123d336c",
   "metadata": {},
   "source": [
    "# 4. Feature correlation heatmap\n",
    "print(\"Generating correlation heatmap...\")\n",
    "selected_features = feature_cols[:20]\n",
    "corr_matrix = df[selected_features].corr()\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", center=0, annot=False, square=True)\n",
    "plt.title('Feature Correlation Heatmap (First 20 Features)', fontsize=28, pad=25)\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.xlabel('Features', fontsize=26, labelpad=20)\n",
    "plt.ylabel('Features', fontsize=26, labelpad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "corr_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_correlation\")\n",
    "save_plot(plt.gcf(), corr_path)\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a871bd1eb2c5638",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Feature correlation heatmaps for each class separately\n",
    "print(\"Generating correlation heatmaps for each class...\")\n",
    "selected_features = feature_cols[:20]  # First 20 features\n",
    "\n",
    "# Set font to Times New Roman\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# Generate separate correlation heatmap for each class\n",
    "for class_name in CLASSES:\n",
    "    print(f\"Creating correlation heatmap for {class_name} class...\")\n",
    "\n",
    "    # Filter data for this class only\n",
    "    class_df = df[df['class'] == class_name]\n",
    "\n",
    "    # Calculate correlation matrix for this class\n",
    "    class_corr_matrix = class_df[selected_features].corr()\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(20, 16))\n",
    "\n",
    "    # Generate heatmap with consistent color scaling\n",
    "    sns.heatmap(class_corr_matrix, cmap=\"coolwarm\", center=0, annot=False, square=True, vmin=-1, vmax=1)\n",
    "\n",
    "    # Add title and labels with larger font sizes\n",
    "    plt.title(f'Feature Correlation Heatmap - {class_name} Class (First 20 Features)', fontsize=28, pad=25)\n",
    "    plt.xlabel('Features', fontsize=26, labelpad=20)\n",
    "    plt.ylabel('Features', fontsize=26, labelpad=20)\n",
    "\n",
    "    # Increase tick label font sizes\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot with class-specific name\n",
    "    corr_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_correlation_{class_name}\")\n",
    "    save_plot(plt.gcf(), corr_path)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "# Also create a combined heatmap for comparison\n",
    "print(\"Creating combined correlation heatmap (all classes)...\")\n",
    "corr_matrix = df[selected_features].corr()\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", center=0, annot=False, square=True, vmin=-1, vmax=1)\n",
    "plt.title('Feature Correlation Heatmap - All Classes (First 20 Features)', fontsize=28, pad=25)\n",
    "plt.xlabel('Features', fontsize=26, labelpad=20)\n",
    "plt.ylabel('Features', fontsize=26, labelpad=20)\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "corr_path = os.path.join(OUTPUT_DIR, f\"{feature_extract_file_name}_correlation_All\")\n",
    "save_plot(plt.gcf(), corr_path)\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "print(\"Feature extraction and visualization complete!\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
